\chapter*{Abstract}

Relation Extraction is the task of detecting and classifying semantic relationship 
between named entities (NE).

For more than a decade, many works have been done on this subject but recently
almost all the proposed models benefits from available large scale knowledge
bases specially Freebase. The main challenge is how to fully benefit from
knowledge encoded in KBs and how to link it to a corpus. Having continuous
vector representations of this knowledge has been shown to be effective for
these tasks.

A new method and formalization for encoding KB facts is proposed in this
work which employs the techniques of representation learning for relation discovery.
 In our method, we link a corpus to a knowledge base (KB)
and learns informative features for NEs and relations jointly using
\emph{representation learning} methods. With these learned features
we are able to predict true relations between NEs.
We have evaluated our model on Freebase relations and our best model
\emph{Text+KB} has been shown to have  several orders of
magnitude better performance than the related previous work. While the rank
of true relations in (micro) average is 71.11 among predicted relations for
previous work, our rank average is 6.72. For previous work, only 67\% of
true relations are among top 100 reported relations in average, our reported top
100 relations contains 98.85\% of true predictions.

\vspace{3cm}

\textbf{Keywords:} Relation Discovery, Representation Learning, Machine
Learning, Semantics
